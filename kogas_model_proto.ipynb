{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "from   datetime import datetime, date\n",
    "# pd.set_option('display.notebook_repr_html', False)\n",
    "# pd.set_option('display.max_columns', 7)\n",
    "# pd.set_option('display.max_rows', 10)\n",
    "# pd.set_option('display.width', 60)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import glob\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using merged files\n",
    "\n",
    "os.chdir('최종합본')\n",
    "\n",
    "\n",
    "files_for_day = []\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    files_for_day.append(file)\n",
    "\n",
    "def minus_to_zero(x):\n",
    "    if x < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "## Make dataset for train\n",
    "for i in range(len(files_for_day)):\n",
    "    tmp_data = pd.read_csv(files_for_day[i])\n",
    "    tmp_data['Time_conv'] = pd.to_datetime(tmp_data['Time_conv'], format = \"%Y/%m/%d %H:%M:%S.%f\")\n",
    "    tmp_data = tmp_data[540:-900]\n",
    "    tmp_data['Time_conv_day'] = pd.to_datetime(tmp_data['Time_conv'].map(lambda x: x.strftime('%Y/%m/%d')))\n",
    "    tmp_data[files_for_day[i][:-4]+'_전류값1'] = tmp_data[files_for_day[i][:-4]+'_전류값1'].apply(minus_to_zero)\n",
    "    grouped_data_feature = tmp_data.groupby('Time_conv_day', as_index=False).mean()\n",
    "    grouped_data_target = tmp_data.groupby('Time_conv_day', as_index=False).sum()\n",
    "    tmp_data_fin = grouped_data_feature\n",
    "    tmp_data_fin[[files_for_day[i][:-4]+'_유량1', files_for_day[i][:-4]+'_전류값1']] = grouped_data_target[[files_for_day[i][:-4]+'_유량1', files_for_day[i][:-4]+'_전류값1']]\n",
    "    tmp_data_fin[[files_for_day[i][:-4]+'_유량1', files_for_day[i][:-4]+'_전류값1']] = tmp_data_fin[[files_for_day[i][:-4]+'_유량1', files_for_day[i][:-4]+'_전류값1']].shift(periods=-1)\n",
    "    tmp_data_fin = tmp_data_fin[:-1]\n",
    "    tmp_data_fin.to_csv('day_'+files_for_day[i], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting models\n",
    "\n",
    "def LR_result(X_train, y_train, X_test, y_test):\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_preds = lr.predict(X_test)\n",
    "    y_preds2 = lr.predict(X_train)\n",
    "    mse = mean_squared_error(y_test, y_preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_preds)\n",
    "    mse2 = mean_squared_error(y_train, y_preds2)\n",
    "    rmse2 = np.sqrt(mse2)\n",
    "    mae2 = mean_absolute_error(y_train, y_preds2)\n",
    "    result_test = 'MSE : {0:.3f}, RMSE : {1:.3f}, MAE : {2:.3f}'.format(mse, rmse, mae)\n",
    "    result_train = 'MSE : {0:.3f}, RMSE : {1:.3f}, MAE : {2:.3f}'.format(mse2, rmse2, mae2)\n",
    "    return {'Test score' : result_test, 'Test Prediction' :y_preds, 'Test True':np.array(y_test),\n",
    "            'Train score' : result_train, 'Train Prediction' :y_preds2, 'Train True':np.array(y_train)}\n",
    "\n",
    "def LAS_result(X_train, y_train, X_test, y_test):\n",
    "    las = Lasso()\n",
    "    las.fit(X_train, y_train)\n",
    "    y_preds = las.predict(X_test)\n",
    "    y_preds2 = las.predict(X_train)\n",
    "    mse = mean_squared_error(y_test, y_preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_preds)\n",
    "    mse2 = mean_squared_error(y_train, y_preds2)\n",
    "    rmse2 = np.sqrt(mse2)\n",
    "    mae2 = mean_absolute_error(y_train, y_preds2)\n",
    "    result_test = 'MSE : {0:.3f}, RMSE : {1:.3f}, MAE : {2:.3f}'.format(mse, rmse, mae)\n",
    "    result_train = 'MSE : {0:.3f}, RMSE : {1:.3f}, MAE : {2:.3f}'.format(mse2, rmse2, mae2)\n",
    "    return {'Test score' : result_test, 'Test Prediction' :y_preds, 'Test True':np.array(y_test),\n",
    "            'Train score' : result_train, 'Train Prediction' :y_preds2, 'Train True':np.array(y_train)}\n",
    "\n",
    "def RID_result(X_train, y_train, X_test, y_test):\n",
    "    rid = Ridge()\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_preds = rid.predict(X_test)\n",
    "    y_preds2 = rid.predict(X_train)\n",
    "    mse = mean_squared_error(y_test, y_preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_preds)\n",
    "    mse2 = mean_squared_error(y_train, y_preds2)\n",
    "    rmse2 = np.sqrt(mse2)\n",
    "    mae2 = mean_absolute_error(y_train, y_preds2)\n",
    "    result_test = 'MSE : {0:.3f}, RMSE : {1:.3f}, MAE : {2:.3f}'.format(mse, rmse, mae)\n",
    "    result_train = 'MSE : {0:.3f}, RMSE : {1:.3f}, MAE : {2:.3f}'.format(mse2, rmse2, mae2)\n",
    "    return {'Test score' : result_test, 'Test Prediction' :y_preds, 'Test True':np.array(y_test),\n",
    "            'Train score' : result_train, 'Train Prediction' :y_preds2, 'Train True':np.array(y_train)}\n",
    "\n",
    "def ELA_result(X_train, y_train, X_test, y_test):\n",
    "    ela = ElasticNet()\n",
    "    ela.fit(X_train, y_train)\n",
    "    y_preds = ela.predict(X_test)\n",
    "    y_preds2 = ela.predict(X_train)\n",
    "    mse = mean_squared_error(y_test, y_preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_preds)\n",
    "    mse2 = mean_squared_error(y_train, y_preds2)\n",
    "    rmse2 = np.sqrt(mse2)\n",
    "    mae2 = mean_absolute_error(y_train, y_preds2)\n",
    "    result_test = 'MSE : {0:.3f}, RMSE : {1:.3f}, MAE : {2:.3f}'.format(mse, rmse, mae)\n",
    "    result_train = 'MSE : {0:.3f}, RMSE : {1:.3f}, MAE : {2:.3f}'.format(mse2, rmse2, mae2)\n",
    "    return {'Test score' : result_test, 'Test Prediction' :y_preds, 'Test True':np.array(y_test),\n",
    "            'Train score' : result_train, 'Train Prediction' :y_preds2, 'Train True':np.array(y_train)}\n",
    "\n",
    "def SVR_result(X_train, y_train, X_test, y_test):\n",
    "    svr = SVR()\n",
    "    svr.fit(X_train, y_train)\n",
    "    y_preds = svr.predict(X_test)\n",
    "    y_preds2 = svr.predict(X_train)\n",
    "    mse = mean_squared_error(y_test, y_preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_preds)\n",
    "    mse2 = mean_squared_error(y_train, y_preds2)\n",
    "    rmse2 = np.sqrt(mse2)\n",
    "    mae2 = mean_absolute_error(y_train, y_preds2)\n",
    "    result_test = 'MSE : {0:.3f}, RMSE : {1:.3f}, MAE : {2:.3f}'.format(mse, rmse, mae)\n",
    "    result_train = 'MSE : {0:.3f}, RMSE : {1:.3f}, MAE : {2:.3f}'.format(mse2, rmse2, mae2)\n",
    "    return {'Test score' : result_test, 'Test Prediction' :y_preds, 'Test True':np.array(y_test),\n",
    "            'Train score' : result_train, 'Train Prediction' :y_preds2, 'Train True':np.array(y_train)}\n",
    "\n",
    "def RFR_result(X_train, y_train, X_test, y_test):\n",
    "    rfr = RandomForestRegressor()\n",
    "    rfr.fit(X_train, y_train)\n",
    "    y_preds = rfr.predict(X_test)\n",
    "    y_preds2 = rfr.predict(X_train)\n",
    "    mse = mean_squared_error(y_test, y_preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_preds)\n",
    "    mse2 = mean_squared_error(y_train, y_preds2)\n",
    "    rmse2 = np.sqrt(mse2)\n",
    "    mae2 = mean_absolute_error(y_train, y_preds2)\n",
    "    result_test = 'MSE : {0:.3f}, RMSE : {1:.3f}, MAE : {2:.3f}'.format(mse, rmse, mae)\n",
    "    result_train = 'MSE : {0:.3f}, RMSE : {1:.3f}, MAE : {2:.3f}'.format(mse2, rmse2, mae2)\n",
    "    return {'Test score' : result_test, 'Test Prediction' :y_preds, 'Test True':np.array(y_test),\n",
    "            'Train score' : result_train, 'Train Prediction' :y_preds2, 'Train True':np.array(y_train)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cross-Validation\n",
    "\n",
    "os.chdir('H:\\gimys\\최종합본\\day1007')\n",
    "files_for_day = []\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    files_for_day.append(file)\n",
    "\n",
    "def model_result_dict(files_for_day):\n",
    "    result_dict = {}\n",
    "    # for j in range(len(files_for_day)):\n",
    "    for j in range(len(files_for_day)):\n",
    "        tmp_data_fin = pd.read_csv(files_for_day[j])\n",
    "        tmp_data_fin['Target'] = tmp_data_fin[files_for_day[j][4:-4]+'_전류값1']/tmp_data_fin[files_for_day[j][4:-4]+'_유량1']\n",
    "        tmp_data_fin['Day'] = tmp_data_fin['Time_conv_day'].astype(str).str[8:10]\n",
    "        \n",
    "        tmp_data_fin = tmp_data_fin.replace(np.NaN, 0)\n",
    "        tmp_data_fin = tmp_data_fin.replace(np.inf, 0)\n",
    "        tmp_data_fin = tmp_data_fin.replace(-(np.inf), 0)\n",
    "        tmp_data_fin_modi = tmp_data_fin.iloc[np.where(tmp_data_fin['Target'] != 0)[0]]\n",
    "        tmp_data_fin_modi = tmp_data_fin_modi.iloc[np.where((tmp_data_fin_modi['Target'] <= 0.4) & (tmp_data_fin_modi['Target'] >= 0.1))[0]]\n",
    "        \n",
    "        ## index split\n",
    "        X = tmp_data_fin_modi.values\n",
    "        set_splits = 5\n",
    "        splits = TimeSeriesSplit(n_splits=set_splits)\n",
    "    \n",
    "        ## set feature and target\n",
    "        index_list = tmp_data_fin_modi.columns.tolist()\n",
    "        index_list.pop(index_list.index(files_for_day[j][4:-4]+'_유량1'))\n",
    "        index_list.pop(index_list.index(files_for_day[j][4:-4]+'_전류값1'))\n",
    "        index_list.pop(index_list.index('Target'))\n",
    "        index_list.pop(index_list.index('Time_conv_day'))\n",
    "        feature_label = index_list\n",
    "        target_label = ['Target']\n",
    "        \n",
    "        \n",
    "#         for k in range(set_splits):\n",
    "#             tmp_train = tmp_data_fin_modi.iloc[list(splits.split(X))[k][0]]\n",
    "#             tmp_test = tmp_data_fin_modi.iloc[list(splits.split(X))[k][1]]\n",
    "#             X_train, y_train = tmp_train[feature_label], tmp_train[target_label]\n",
    "#             X_test, y_test = tmp_test[feature_label], tmp_test[target_label]\n",
    "#             result_dict[files_for_day[j][:-4]+'_sp'+str(k)] =  LR_result(X_train, y_train, X_test, y_test)\n",
    "        k = 4\n",
    "        tmp_train = tmp_data_fin_modi.iloc[list(splits.split(X))[k][0]]\n",
    "        tmp_test = tmp_data_fin_modi.iloc[list(splits.split(X))[k][1]]\n",
    "        X_train, y_train = tmp_train[feature_label], tmp_train[target_label]\n",
    "        X_test, y_test = tmp_test[feature_label], tmp_test[target_label]\n",
    "        result_dict[files_for_day[j][:-4]+'_sp'+str(k)] =  RFR_result(X_train, y_train, X_test, y_test)\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "## modify dataset\n",
    "y_train_modi = y_train.iloc[np.where(y_train != 0)[0]]\n",
    "X_train_modi = X_train.iloc[np.where(y_train != 0)[0]]\n",
    "y_test_modi = y_test.iloc[np.where(y_test != 0)[0]]\n",
    "X_test_modi = X_test.iloc[np.where(y_test != 0)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make 'D-1 ~ D-5' data (Data Shift)\n",
    "### add weather data\n",
    "data = pd.read_csv('H:\\gimys\\weather_data.csv', encoding='euc-kr')\n",
    "\n",
    "for i in (range(1, 6)):\n",
    "    globals()[\"data_d_\" + str(i)] = data.shift(i)\n",
    "\n",
    "naming = list()\n",
    "for j in range(1,6):\n",
    "    for i in range(len(list(data.columns))):        \n",
    "        naming.append(list(globals()[\"data_d_\" + str(j)].columns)[i]+'_d-{}'.format(j))\n",
    "    globals()[\"data_d_\" + str(j)].set_axis(naming, axis = 1)\n",
    "    naming = list()\n",
    "total_data = pd.concat([data, data_d_1, data_d_2, data_d_3, data_d_4, data_d_5], axis = 1)\n",
    "\n",
    "total_data.to_csv('weather_d5.csv', index=False)\n",
    "del total_data\n",
    "\n",
    "weather_data = pd.read_csv('weather_d5.csv')\n",
    "weather_data =weather_data.drop(columns=['일시', '일시_d-5', '일시_d-4', '일시_d-3', '일시_d-2', '일시_d-1'])\n",
    "\n",
    "\n",
    "## Modeling using only shifted data\n",
    "\n",
    "os.chdir('H:\\gimys\\최종합본\\day1007')\n",
    "files_for_day = []\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    files_for_day.append(file)\n",
    "# weather_data = pd.read_csv('../../weather_data.csv', encoding = 'euc-kr')\n",
    "# weather_data = weather_data.drop(columns=['지점', 'Month', 'Year', 'Weekday', 'Time'])\n",
    "# weather_data = weather_data.rename(columns = {'일시' : 'Time_conv_day'}).copy()\n",
    "for k in range(len(files_for_day)):\n",
    "    data = pd.read_csv(files_for_day[k])\n",
    "#     data = data.drop(columns=['Time_conv_day'])\n",
    "    \n",
    "    for m in (range(1, 6)):\n",
    "        globals()[\"data_d_\" + str(m)] = data.shift(m)\n",
    "    \n",
    "    naming = list()\n",
    "    for j in range(1,6):\n",
    "        for i in range(len(list(data.columns))):        \n",
    "            naming.append(list(globals()[\"data_d_\" + str(j)].columns)[i]+'_d-{}'.format(j))\n",
    "        globals()[\"data_d_\" + str(j)].set_axis(naming, axis = 1)\n",
    "        naming = list()\n",
    "    total_data = pd.concat([data, data_d_1, data_d_2, data_d_3, data_d_4, data_d_5], axis = 1)\n",
    "    total_data = total_data[5:]\n",
    "#     total_weather_data = pd.merge(total_data, weather_data, how='left', on = 'Time_conv_day')\n",
    "    total_data =total_data.drop(columns=['Time_conv_day', 'Time_conv_day_d-5', 'Time_conv_day_d-4', 'Time_conv_day_d-3',\n",
    "                                                         'Time_conv_day_d-2', 'Time_conv_day_d-1'])    \n",
    "    total_data.to_csv('shift'+files_for_day[k], index=False)\n",
    "    print(files_for_day[k])\n",
    "    \n",
    "## Apply Data Shift\n",
    "def model_result_dict_shift(files_for_day):\n",
    "    result_dict = {}\n",
    "    # for j in range(len(files_for_day)):\n",
    "    for j in range(len(files_for_day)):\n",
    "        tmp_data_fin = pd.read_csv(files_for_day[j])\n",
    "        tmp_data_fin = pd.get_dummies(tmp_data_fin)\n",
    "        tmp_data_fin['Target'] = tmp_data_fin[files_for_day[j][9:-4]+'_전류값1']/tmp_data_fin[files_for_day[j][9:-4]+'_유량1']\n",
    "        tmp_data_fin['Target_d-1'] = tmp_data_fin[files_for_day[j][9:-4]+'_전류값1_d-1']/tmp_data_fin[files_for_day[j][9:-4]+'_유량1_d-1']\n",
    "        tmp_data_fin['Target_d-2'] = tmp_data_fin[files_for_day[j][9:-4]+'_전류값1_d-2']/tmp_data_fin[files_for_day[j][9:-4]+'_유량1_d-2']\n",
    "        tmp_data_fin['Target_d-3'] = tmp_data_fin[files_for_day[j][9:-4]+'_전류값1_d-3']/tmp_data_fin[files_for_day[j][9:-4]+'_유량1_d-3']\n",
    "        tmp_data_fin['Target_d-4'] = tmp_data_fin[files_for_day[j][9:-4]+'_전류값1_d-4']/tmp_data_fin[files_for_day[j][9:-4]+'_유량1_d-4']\n",
    "        tmp_data_fin['Target_d-5'] = tmp_data_fin[files_for_day[j][9:-4]+'_전류값1_d-5']/tmp_data_fin[files_for_day[j][9:-4]+'_유량1_d-5']\n",
    "        \n",
    "\n",
    "        tmp_data_fin = tmp_data_fin.replace(np.NaN, 0)\n",
    "        tmp_data_fin = tmp_data_fin.replace(np.inf, 0)\n",
    "        tmp_data_fin = tmp_data_fin.replace(-(np.inf), 0)\n",
    "        tmp_data_fin_modi = tmp_data_fin.iloc[np.where(tmp_data_fin['Target'] != 0)[0]]\n",
    "        tmp_data_fin_modi = tmp_data_fin_modi.iloc[np.where((tmp_data_fin_modi['Target'] <= 0.4) & (tmp_data_fin_modi['Target'] >= 0.1))[0]]        \n",
    "        ## index split\n",
    "        X = tmp_data_fin_modi.values\n",
    "        set_splits = 5\n",
    "        splits = TimeSeriesSplit(n_splits=set_splits)\n",
    "    \n",
    "        ## set feature and target\n",
    "        ## 유량과 전류값은 target에 포함되므로 제거하고, Time_conv_day는 분리된 Year, Month, Day가 대체\n",
    "        index_list = tmp_data_fin_modi.columns.tolist()\n",
    "        index_list.pop(index_list.index(files_for_day[j][9:-4]+'_유량1'))\n",
    "        index_list.pop(index_list.index(files_for_day[j][9:-4]+'_전류값1'))\n",
    "        index_list.pop(index_list.index('Target'))\n",
    "        feature_label = index_list\n",
    "        target_label = ['Target']\n",
    "        \n",
    "        \n",
    "#         for k in range(set_splits):\n",
    "#             tmp_train = tmp_data_fin_modi.iloc[list(splits.split(X))[k][0]]\n",
    "#             tmp_test = tmp_data_fin_modi.iloc[list(splits.split(X))[k][1]]\n",
    "#             X_train, y_train = tmp_train[feature_label], tmp_train[target_label]\n",
    "#             X_test, y_test = tmp_test[feature_label], tmp_test[target_label]\n",
    "#             result_dict[files_for_day[j][:-4]+'_sp'+str(k)] =  LR_result(X_train, y_train, X_test, y_test)\n",
    "        k = 4\n",
    "        tmp_train = tmp_data_fin_modi.iloc[list(splits.split(X))[k][0]]\n",
    "        tmp_test = tmp_data_fin_modi.iloc[list(splits.split(X))[k][1]]\n",
    "        X_train, y_train = tmp_train[feature_label], tmp_train[target_label]\n",
    "        X_test, y_test = tmp_test[feature_label], tmp_test[target_label]\n",
    "        result_dict[files_for_day[j][:-4]+'_sp'+str(k)] =  RFR_result(X_train, y_train, X_test, y_test)            \n",
    "    return result_dict\n",
    "\n",
    "\n",
    "save_result_shift = model_result_dict_shift(files_for_day)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
