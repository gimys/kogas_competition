{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random Forest Regressor Base Line\n",
    "### To use another model, modify 'RFR_result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "from   datetime import datetime, date\n",
    "# pd.set_option('display.notebook_repr_html', False)\n",
    "# pd.set_option('display.max_columns', 7)\n",
    "# pd.set_option('display.max_rows', 10)\n",
    "# pd.set_option('display.width', 60)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import glob\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_result(X_train, y_train, X_test, y_test):\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_preds = lr.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_preds)\n",
    "    y_preds_train = lr.predict(X_train)    \n",
    "    mse_train = mean_squared_error(y_train, y_preds_train)\n",
    "    rmse_train = np.sqrt(mse_train)    \n",
    "    mae_train = mean_absolute_error(y_train, y_preds_train)\n",
    "    result_1 = 'MSE : {0:.6f}, RMSE : {1:.6f}, MAE : {1:.6f}'.format(mse, rmse, mae)\n",
    "    result_2 = 'MSE : {0:.6f}, RMSE : {1:.6f}, MAE : {1:.6f}'.format(mse_train, rmse_train, mae_train)\n",
    "    return {'Test' : result_1, 'Train' : result_2,\n",
    "             'Test_Prediction' :y_preds, 'Test_True':np.array(y_test),\n",
    "             'Train_Prediction' :y_preds_train, 'Train_True':np.array(y_train)}\n",
    "\n",
    "def LAS_result(X_train, y_train, X_test, y_test):\n",
    "    las = Lasso()\n",
    "    las.fit(X_train, y_train)\n",
    "    y_preds = las.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_preds)\n",
    "    y_preds_train = las.predict(X_train)    \n",
    "    mse_train = mean_squared_error(y_train, y_preds_train)\n",
    "    rmse_train = np.sqrt(mse_train)    \n",
    "    mae_train = mean_absolute_error(y_train, y_preds_train)\n",
    "    result_1 = 'MSE : {0:.6f}, RMSE : {1:.6f}, MAE : {1:.6f}'.format(mse, rmse, mae)\n",
    "    result_2 = 'MSE : {0:.6f}, RMSE : {1:.6f}, MAE : {1:.6f}'.format(mse_train, rmse_train, mae_train)\n",
    "    return {'Test' : result_1, 'Train' : result_2,\n",
    "             'Test_Prediction' :y_preds, 'Test_True':np.array(y_test),\n",
    "             'Train_Prediction' :y_preds_train, 'Train_True':np.array(y_train)}\n",
    "\n",
    "def RID_result(X_train, y_train, X_test, y_test):\n",
    "    rid = Ridge()\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_preds = rid.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_preds)\n",
    "    y_preds_train = rid.predict(X_train)    \n",
    "    mse_train = mean_squared_error(y_train, y_preds_train)\n",
    "    rmse_train = np.sqrt(mse_train)    \n",
    "    mae_train = mean_absolute_error(y_train, y_preds_train)\n",
    "    result_1 = 'MSE : {0:.6f}, RMSE : {1:.6f}, MAE : {1:.6f}'.format(mse, rmse, mae)\n",
    "    result_2 = 'MSE : {0:.6f}, RMSE : {1:.6f}, MAE : {1:.6f}'.format(mse_train, rmse_train, mae_train)\n",
    "    return {'Test' : result_1, 'Train' : result_2,\n",
    "             'Test_Prediction' :y_preds, 'Test_True':np.array(y_test),\n",
    "             'Train_Prediction' :y_preds_train, 'Train_True':np.array(y_train)}\n",
    "\n",
    "def ELA_result(X_train, y_train, X_test, y_test):\n",
    "    ela = ElasticNet()\n",
    "    ela.fit(X_train, y_train)\n",
    "    y_preds = ela.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_preds)\n",
    "    y_preds_train = ela.predict(X_train)    \n",
    "    mse_train = mean_squared_error(y_train, y_preds_train)\n",
    "    rmse_train = np.sqrt(mse_train)    \n",
    "    mae_train = mean_absolute_error(y_train, y_preds_train)\n",
    "    result_1 = 'MSE : {0:.6f}, RMSE : {1:.6f}, MAE : {1:.6f}'.format(mse, rmse, mae)\n",
    "    result_2 = 'MSE : {0:.6f}, RMSE : {1:.6f}, MAE : {1:.6f}'.format(mse_train, rmse_train, mae_train)\n",
    "    return {'Test' : result_1, 'Train' : result_2,\n",
    "             'Test_Prediction' :y_preds, 'Test_True':np.array(y_test),\n",
    "             'Train_Prediction' :y_preds_train, 'Train_True':np.array(y_train)}\n",
    "\n",
    "def RFR_result(X_train, y_train, X_test, y_test):\n",
    "    rfr = RandomForestRegressor()\n",
    "    rfr.fit(X_train, y_train)\n",
    "    y_preds = rfr.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_preds)\n",
    "    y_preds_train = rfr.predict(X_train)    \n",
    "    mse_train = mean_squared_error(y_train, y_preds_train)\n",
    "    rmse_train = np.sqrt(mse_train)    \n",
    "    mae_train = mean_absolute_error(y_train, y_preds_train)\n",
    "    result_1 = 'MSE : {0:.6f}, RMSE : {1:.6f}, MAE : {1:.6f}'.format(mse, rmse, mae)\n",
    "    result_2 = 'MSE : {0:.6f}, RMSE : {1:.6f}, MAE : {1:.6f}'.format(mse_train, rmse_train, mae_train)\n",
    "    return {'Test' : result_1, 'Train' : result_2,\n",
    "             'Test_Prediction' :y_preds, 'Test_True':np.array(y_test),\n",
    "             'Train_Prediction' :y_preds_train, 'Train_True':np.array(y_train)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modelling Day Data\n",
    "\n",
    "os.chdir('S:\\\\Data\\\\Daily')\n",
    "files_for_day = []\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    files_for_day.append(file)\n",
    "\n",
    "def model_result_dict(files_for_day):\n",
    "    result_dict = {}\n",
    "    # for j in range(len(files_for_day)):\n",
    "    for j in range(len(files_for_day)):\n",
    "        tmp_data_fin = pd.read_csv(files_for_day[j])\n",
    "        tmp_data_fin['Target'] = tmp_data_fin[files_for_day[j][4:-4]+'_전류값1']/tmp_data_fin[files_for_day[j][4:-4]+'_유량1']\n",
    "#         tmp_data_fin['Year'] = tmp_data_fin['Time_conv_day'].astype(str).str[0:4]\n",
    "#         tmp_data_fin['Month'] = tmp_data_fin['Time_conv_day'].astype(str).str[5:7]\n",
    "        tmp_data_fin['Day'] = tmp_data_fin['Time_conv_day'].astype(str).str[8:10]\n",
    "        \n",
    "        ### 주의!!! 일단 모델 돌아가는 것을 확인하기 위해 모든 NaN을 0으로 변경함!!!\n",
    "        ### 추후 각 NaN에 대한 변환 방향성이 필요!!\n",
    "        tmp_data_fin = tmp_data_fin.replace(np.NaN, 0)\n",
    "        tmp_data_fin = tmp_data_fin.replace(np.inf, 0)\n",
    "        tmp_data_fin = tmp_data_fin.replace(-(np.inf), 0)\n",
    "        tmp_data_fin_modi = tmp_data_fin.iloc[np.where(tmp_data_fin['Target'] != 0)[0]]\n",
    "        tmp_data_fin_modi = tmp_data_fin_modi.iloc[np.where((tmp_data_fin_modi['Target'] <= 0.4) & (tmp_data_fin_modi['Target'] >= 0.1))[0]]\n",
    "        \n",
    "        ## index split\n",
    "        X = tmp_data_fin_modi.values\n",
    "        set_splits = 4\n",
    "        splits = TimeSeriesSplit(n_splits=set_splits)\n",
    "    \n",
    "        ## set feature and target\n",
    "        ## 유량과 전류값은 target에 포함되므로 제거하고, Time_conv_day는 분리된 Year, Month, Day가 대체\n",
    "        index_list = tmp_data_fin_modi.columns.tolist()\n",
    "        index_list.pop(index_list.index(files_for_day[j][4:-4]+'_유량1'))\n",
    "        index_list.pop(index_list.index(files_for_day[j][4:-4]+'_전류값1'))\n",
    "        index_list.pop(index_list.index('Target'))\n",
    "        index_list.pop(index_list.index('Time_conv_day'))\n",
    "        feature_label = index_list\n",
    "        target_label = ['Target']\n",
    "        \n",
    "        \n",
    "#         for k in range(set_splits):\n",
    "#             tmp_train = tmp_data_fin_modi.iloc[list(splits.split(X))[k][0]]\n",
    "#             tmp_test = tmp_data_fin_modi.iloc[list(splits.split(X))[k][1]]\n",
    "#             X_train, y_train = tmp_train[feature_label], tmp_train[target_label]\n",
    "#             X_test, y_test = tmp_test[feature_label], tmp_test[target_label]\n",
    "#             result_dict[files_for_day[j][:-4]+'_sp'+str(k)] =  LR_result(X_train, y_train, X_test, y_test)\n",
    "        k = 3\n",
    "        tmp_train = tmp_data_fin_modi.iloc[list(splits.split(X))[k][0]]\n",
    "        tmp_test = tmp_data_fin_modi.iloc[list(splits.split(X))[k][1]]\n",
    "        X_train, y_train = tmp_train[feature_label], tmp_train[target_label]\n",
    "        X_test, y_test = tmp_test[feature_label], tmp_test[target_label]\n",
    "        result_dict[files_for_day[j][:-4]+'_sp'+str(k)] =  RFR_result(X_train, y_train, X_test, y_test)\n",
    "    return result_dict\n",
    "\n",
    "save_result = model_result_dict(files_for_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modelling Shifted Data\n",
    "\n",
    "os.chdir('S:\\\\Data\\\\Daily\\\\shift')\n",
    "files_for_day = []\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    files_for_day.append(file)\n",
    "def model_result_dict_shift(files_for_day):\n",
    "    result_dict = {}\n",
    "    # for j in range(len(files_for_day)):\n",
    "    for j in range(len(files_for_day)):\n",
    "        tmp_data_fin = pd.read_csv(files_for_day[j])\n",
    "        tmp_data_fin = pd.get_dummies(tmp_data_fin)\n",
    "        tmp_data_fin['Target'] = tmp_data_fin[files_for_day[j][9:-4]+'_전류값1']/tmp_data_fin[files_for_day[j][9:-4]+'_유량1']\n",
    "        tmp_data_fin['Target_d-1'] = tmp_data_fin[files_for_day[j][9:-4]+'_전류값1_d-1']/tmp_data_fin[files_for_day[j][9:-4]+'_유량1_d-1']\n",
    "        tmp_data_fin['Target_d-2'] = tmp_data_fin[files_for_day[j][9:-4]+'_전류값1_d-2']/tmp_data_fin[files_for_day[j][9:-4]+'_유량1_d-2']\n",
    "        tmp_data_fin['Target_d-3'] = tmp_data_fin[files_for_day[j][9:-4]+'_전류값1_d-3']/tmp_data_fin[files_for_day[j][9:-4]+'_유량1_d-3']\n",
    "        tmp_data_fin['Target_d-4'] = tmp_data_fin[files_for_day[j][9:-4]+'_전류값1_d-4']/tmp_data_fin[files_for_day[j][9:-4]+'_유량1_d-4']\n",
    "        tmp_data_fin['Target_d-5'] = tmp_data_fin[files_for_day[j][9:-4]+'_전류값1_d-5']/tmp_data_fin[files_for_day[j][9:-4]+'_유량1_d-5']\n",
    "        \n",
    "        ### 주의!!! 일단 모델 돌아가는 것을 확인하기 위해 모든 NaN을 0으로 변경함!!!\n",
    "        ### 추후 각 NaN에 대한 변환 방향성이 필요!!\n",
    "        tmp_data_fin = tmp_data_fin.replace(np.NaN, 0)\n",
    "        tmp_data_fin = tmp_data_fin.replace(np.inf, 0)\n",
    "        tmp_data_fin = tmp_data_fin.replace(-(np.inf), 0)\n",
    "        tmp_data_fin_modi = tmp_data_fin.iloc[np.where(tmp_data_fin['Target'] != 0)[0]]\n",
    "        tmp_data_fin_modi = tmp_data_fin_modi.iloc[np.where((tmp_data_fin_modi['Target'] <= 0.4) & (tmp_data_fin_modi['Target'] >= 0.1))[0]]        \n",
    "        ## index split\n",
    "        X = tmp_data_fin_modi.values\n",
    "        set_splits = 4\n",
    "        splits = TimeSeriesSplit(n_splits=set_splits)\n",
    "    \n",
    "        ## set feature and target\n",
    "        ## 유량과 전류값은 target에 포함되므로 제거하고, Time_conv_day는 분리된 Year, Month, Day가 대체\n",
    "        index_list = tmp_data_fin_modi.columns.tolist()\n",
    "        index_list.pop(index_list.index(files_for_day[j][9:-4]+'_유량1'))\n",
    "        index_list.pop(index_list.index(files_for_day[j][9:-4]+'_전류값1'))\n",
    "        index_list.pop(index_list.index('Target'))\n",
    "        feature_label = index_list\n",
    "        target_label = ['Target']\n",
    "\n",
    "        k = 3\n",
    "        tmp_train = tmp_data_fin_modi.iloc[list(splits.split(X))[k][0]]\n",
    "        tmp_test = tmp_data_fin_modi.iloc[list(splits.split(X))[k][1]]\n",
    "        X_train, y_train = tmp_train[feature_label], tmp_train[target_label]\n",
    "        X_test, y_test = tmp_test[feature_label], tmp_test[target_label]\n",
    "        result_dict[files_for_day[j][:-4]+'_sp'+str(k)] =  RFR_result(X_train, y_train, X_test, y_test)            \n",
    "    return result_dict\n",
    "\n",
    "save_result_shift = model_result_dict_shift(files_for_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modelling Shifted Weather Data\n",
    "\n",
    "os.chdir('S:\\\\Data\\\\Daily\\\\shift_weather')\n",
    "files_for_day = []\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    files_for_day.append(file)\n",
    "def model_result_dict_weather(files_for_day):\n",
    "    result_dict = {}\n",
    "    # for j in range(len(files_for_day)):\n",
    "    for j in range(len(files_for_day)):\n",
    "        tmp_data_fin = pd.read_csv(files_for_day[j])\n",
    "        tmp_data_fin = pd.get_dummies(tmp_data_fin)\n",
    "        tmp_data_fin['Target'] = tmp_data_fin[files_for_day[j][17:-4]+'_전류값1']/tmp_data_fin[files_for_day[j][17:-4]+'_유량1']\n",
    "        tmp_data_fin['Target_d-1'] = tmp_data_fin[files_for_day[j][17:-4]+'_전류값1_d-1']/tmp_data_fin[files_for_day[j][17:-4]+'_유량1_d-1']\n",
    "        tmp_data_fin['Target_d-2'] = tmp_data_fin[files_for_day[j][17:-4]+'_전류값1_d-2']/tmp_data_fin[files_for_day[j][17:-4]+'_유량1_d-2']\n",
    "        tmp_data_fin['Target_d-3'] = tmp_data_fin[files_for_day[j][17:-4]+'_전류값1_d-3']/tmp_data_fin[files_for_day[j][17:-4]+'_유량1_d-3']\n",
    "        tmp_data_fin['Target_d-4'] = tmp_data_fin[files_for_day[j][17:-4]+'_전류값1_d-4']/tmp_data_fin[files_for_day[j][17:-4]+'_유량1_d-4']\n",
    "        tmp_data_fin['Target_d-5'] = tmp_data_fin[files_for_day[j][17:-4]+'_전류값1_d-5']/tmp_data_fin[files_for_day[j][17:-4]+'_유량1_d-5']\n",
    "        \n",
    "        ### 주의!!! 일단 모델 돌아가는 것을 확인하기 위해 모든 NaN을 0으로 변경함!!!\n",
    "        ### 추후 각 NaN에 대한 변환 방향성이 필요!!\n",
    "        tmp_data_fin = tmp_data_fin.replace(np.NaN, 0)\n",
    "        tmp_data_fin = tmp_data_fin.replace(np.inf, 0)\n",
    "        tmp_data_fin = tmp_data_fin.replace(-(np.inf), 0)\n",
    "        tmp_data_fin_modi = tmp_data_fin.iloc[np.where(tmp_data_fin['Target'] != 0)[0]]\n",
    "        tmp_data_fin_modi = tmp_data_fin_modi.iloc[np.where((tmp_data_fin_modi['Target'] <= 0.4) & (tmp_data_fin_modi['Target'] >= 0.1))[0]]        \n",
    "        ## index split\n",
    "        X = tmp_data_fin_modi.values\n",
    "        set_splits = 4\n",
    "        splits = TimeSeriesSplit(n_splits=set_splits)\n",
    "    \n",
    "        ## set feature and target\n",
    "        ## 유량과 전류값은 target에 포함되므로 제거하고, Time_conv_day는 분리된 Year, Month, Day가 대체\n",
    "        index_list = tmp_data_fin_modi.columns.tolist()\n",
    "        index_list.pop(index_list.index(files_for_day[j][17:-4]+'_유량1'))\n",
    "        index_list.pop(index_list.index(files_for_day[j][17:-4]+'_전류값1'))\n",
    "        index_list.pop(index_list.index('Target'))\n",
    "        feature_label = index_list\n",
    "        target_label = ['Target']\n",
    "\n",
    "        k = 3\n",
    "        tmp_train = tmp_data_fin_modi.iloc[list(splits.split(X))[k][0]]\n",
    "        tmp_test = tmp_data_fin_modi.iloc[list(splits.split(X))[k][1]]\n",
    "        X_train, y_train = tmp_train[feature_label], tmp_train[target_label]\n",
    "        X_test, y_test = tmp_test[feature_label], tmp_test[target_label]\n",
    "        result_dict[files_for_day[j][:-4]+'_sp'+str(k)] =  RFR_result(X_train, y_train, X_test, y_test)            \n",
    "    return result_dict\n",
    "\n",
    "save_result_shifted_weather = model_result_dict_weather(files_for_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modelling Day Weather Data\n",
    "\n",
    "os.chdir('S:Data\\\\Daily\\\\day_weather')\n",
    "files_for_day = []\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    files_for_day.append(file)\n",
    "def model_result_dict_dayweather(files_for_day):\n",
    "    result_dict = {}\n",
    "    # for j in range(len(files_for_day)):\n",
    "    for j in range(len(files_for_day)):\n",
    "        tmp_data_fin = pd.read_csv(files_for_day[j])\n",
    "        tmp_data_fin = pd.get_dummies(tmp_data_fin)\n",
    "        tmp_data_fin['Target'] = tmp_data_fin[files_for_day[j][-9:-4]+'_전류값1']/tmp_data_fin[files_for_day[j][-9:-4]+'_유량1']\n",
    "        \n",
    "        ### 주의!!! 일단 모델 돌아가는 것을 확인하기 위해 모든 NaN을 0으로 변경함!!!\n",
    "        ### 추후 각 NaN에 대한 변환 방향성이 필요!!\n",
    "        tmp_data_fin = tmp_data_fin.replace(np.NaN, 0)\n",
    "        tmp_data_fin = tmp_data_fin.replace(np.inf, 0)\n",
    "        tmp_data_fin = tmp_data_fin.replace(-(np.inf), 0)\n",
    "        tmp_data_fin_modi = tmp_data_fin.iloc[np.where(tmp_data_fin['Target'] != 0)[0]]\n",
    "        tmp_data_fin_modi = tmp_data_fin_modi.iloc[np.where((tmp_data_fin_modi['Target'] <= 0.4) & (tmp_data_fin_modi['Target'] >= 0.1))[0]]        \n",
    "        ## index split\n",
    "        X = tmp_data_fin_modi.values\n",
    "        set_splits = 4\n",
    "        splits = TimeSeriesSplit(n_splits=set_splits)\n",
    "    \n",
    "        ## set feature and target\n",
    "        ## 유량과 전류값은 target에 포함되므로 제거하고, Time_conv_day는 분리된 Year, Month, Day가 대체\n",
    "        index_list = tmp_data_fin_modi.columns.tolist()\n",
    "        index_list.pop(index_list.index(files_for_day[j][-9:-4]+'_유량1'))\n",
    "        index_list.pop(index_list.index(files_for_day[j][-9:-4]+'_전류값1'))\n",
    "        index_list.pop(index_list.index('Target'))\n",
    "        feature_label = index_list\n",
    "        target_label = ['Target']\n",
    "\n",
    "        k = 3\n",
    "        tmp_train = tmp_data_fin_modi.iloc[list(splits.split(X))[k][0]]\n",
    "        tmp_test = tmp_data_fin_modi.iloc[list(splits.split(X))[k][1]]\n",
    "        X_train, y_train = tmp_train[feature_label], tmp_train[target_label]\n",
    "        X_test, y_test = tmp_test[feature_label], tmp_test[target_label]\n",
    "        result_dict[files_for_day[j][:-4]+'_sp'+str(k)] =  RFR_result(X_train, y_train, X_test, y_test)            \n",
    "    return result_dict\n",
    "\n",
    "save_result_dayweather = model_result_dict_dayweather(files_for_day)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
